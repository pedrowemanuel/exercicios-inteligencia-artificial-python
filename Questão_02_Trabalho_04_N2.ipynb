{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWaQaGYBbSnYmkZq6189O8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrowemanuel/exercicios-inteligencia-artificial-python/blob/main/Quest%C3%A3o_02_Trabalho_04_N2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31M2_WkZLpwm",
        "outputId": "7a579aaa-4345-430c-9ae0-ce5263c3e3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1] 0 [0]\n",
            "[1 0] 1 [1]\n",
            "[0 1] 1 [1]\n",
            "[0 0] 1 [1]\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"MLP.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Kt4iefifaaNh0F5Pmq5Tjxt0V-L99F5N\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(6)\n",
        "\n",
        "def sigmoid(x): \n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(sx):\n",
        "    \n",
        "    return sx * (1 - sx)\n",
        "\n",
        "\n",
        "def cost(predicted, truth):\n",
        "    return truth - predicted\n",
        "\n",
        "X = xor_input = np.array([[1,1],[1,0], [0,1], [0,0]])\n",
        "Y = xor_output = np.array([[0, 1, 1, 1]]).T\n",
        "\n",
        "\n",
        "_temp = list(zip(X, Y)) # zip (cria um iterador que agregará elementos de dois ou mais iteráveis.)\n",
        "random.shuffle(_temp)\n",
        "xor_input_shuff, xor_output_shuff = map(np.array, zip(*_temp)) \n",
        "# O map() do Python é uma função interna que permite processar e \n",
        "#transformar todos os itens em um iterável sem usar um loop for \n",
        "#explícito , uma técnica comumente conhecida como mapeamento. \n",
        "#map() é útil quando você precisa aplicar uma função de transformação \n",
        "#a cada item em um iterável e transformá-los em um novo iterável.\n",
        "\n",
        "\n",
        "# Vamos descartar a última linha de dados e usá-la como teste invisível.\n",
        "X = xor_input_shuff[:-1]\n",
        "Y = xor_output_shuff[:-1]\n",
        "\n",
        "\n",
        "# Defina a forma do vetor de peso.\n",
        "num_data, input_dim = X.shape\n",
        "\n",
        "hidden_dim = 5\n",
        "\n",
        "# Inicializa os pesos entre as camadas de entrada e a camada oculta.\n",
        "W1 = np.random.random((input_dim, hidden_dim))\n",
        "\n",
        "\n",
        "# Defina a forma do vetor de saída.\n",
        "output_dim = len(Y.T)\n",
        "\n",
        "# Inicializa os pesos entre as camadas ocultas e a camada de saída.\n",
        "W2 = np.random.random((hidden_dim, output_dim))\n",
        "\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.2\n",
        "\n",
        "for epoch_n in range(num_epochs):\n",
        "    layer0 = X\n",
        "\n",
        "    # Propagação para frente.\n",
        "    \n",
        "\n",
        "    # Dentro do perceptron, Passo 2.\n",
        "    layer1 = sigmoid(np.dot(layer0, W1))\n",
        "    layer2 = sigmoid(np.dot(layer1, W2))\n",
        "\n",
        "\n",
        "    # Retropropagação (Y -> layer2)\n",
        "    \n",
        "    # Quanto perdemos nas previsões?\n",
        "    # Quanto perdemos nas?\n",
        "    layer2_error = cost(layer2, Y)\n",
        "    \n",
        "    # Em que direção está o valor alvo?\n",
        "    # Estávamos realmente próximos? Se sim, não mude muito.\n",
        "    layer2_delta = layer2_error * sigmoid_derivative(layer2)\n",
        "\n",
        "    \n",
        "    \n",
        "    # Retropropagação (camada2 -> camada1)\n",
        "    # Quanto cada valor de layer1 contribuiu para o erro de layer2 (de acordo com os pesos)?\n",
        "    layer1_error = np.dot(layer2_delta, W2.T)\n",
        "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
        "    \n",
        "    # Atualização dos pesos\n",
        "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
        "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)\n",
        "\n",
        "    EQM = (layer2_error/num_epochs)**2\n",
        "\n",
        "for x, y in zip(xor_input, xor_output):\n",
        "    \n",
        "    # Alimente a entrada invisível em W treinado.\n",
        "    layer1_prediction = sigmoid(np.dot(W1.T, x)) \n",
        "    \n",
        "    prediction = layer2_prediction = sigmoid(np.dot(W2.T, layer1_prediction))\n",
        "    print(x, int(prediction > 0.5), y)"
      ]
    }
  ]
}